{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $W_{t}$ be a Brownian motion, and define\n",
    "\n",
    "$ B(t) = \\int_{0}^{t} sign(W(s)) dW(s) $ \n",
    "\n",
    "(i) Show that B(t) is a Brownian Motion.\n",
    "We need to check wheter B(0) is 0 and the quadratic variation of B(t) is t.\n",
    "If we set $B(0) = \\int_{0}^{0} sign(W(s)) dW(s)  = 0$.\n",
    "\n",
    "The quadratic variation is $[B]_{t} = \\int_{0}^{t} sign(W_{s}) ds = t$\n",
    " \n",
    "By Levy's theorem this is a Brownian motion\n",
    "\n",
    "(ii) Use Ito's product rule to compute d[B(t)W(t)]. Integrate both sides of the resulting equation and take expectation. Show that \n",
    "$ E[B(t)W(t)] =0$\n",
    "\n",
    "We remember that Ito's product rule is $d(S_{1}(t) S_{2}(t))  = S_{1}(t) d S_{2}(t) + S_{2}(t) * d S_{1}(t) + d [S_{1}, S_{2}]_{t}$\n",
    "\n",
    "We plug our setting in and get $ d[B(t)W(t)] = B_{t} dW_{t} + sign(W_{t}) W_{t} dW_{t} + sign(W_{t}) dt $\n",
    "\n",
    "We are now integrating the previous equation and get \n",
    "\n",
    "$E[B_{t} W_{t}] = \\int_{0}^{t} E[sign(W_{s})] ds$\n",
    "\n",
    "as the terms from the $ dW_{t} $ part are set to 0.\n",
    "\n",
    "$\\int_{0}^{t} E[1_{W_{s} \\geq 0} + 1_{W_{s} < 0} ] ds = \\frac{1}{2} t  - \\frac{1}{2} t =0 $, as W is 1/2 positive and 1/2 negative, by construction.\n",
    "\n",
    "(iii) Verify that $ d W^{2}(t) = 2 W(t) dW(t) + dt $\n",
    "\n",
    "If we write $ W^{2} $ in terms of f we get $f(x, t) = x^{2}$. We then apply Ito-Doeblins formula to get: $ d f(W(t)) = f' (W(t))d W(t) + \\frac{1}{2} f''(W(t)) dt$, hence we get\n",
    "\n",
    "$ d W^{2} = 2 W(t) d W(t) + \\frac{1}{2} 2 dt = d W^{2}(t) = 2 W(t) dW(t) + dt $, hence we proved our result.\n",
    "\n",
    "(iv) We use Ito's product rule again to get: \n",
    "$ d(B(t) W^{2}(t)) = B(t) d W^{2}(t) + W^{2}(t) d B(t) + d [B(t), W^{2}(t)] = $\n",
    "\n",
    "we now apply the definitions we got and get:\n",
    "\n",
    "$B_{t}(2 W_{t} d W{t}+ dt) + W_{t}^{2} sign(W_{t}) d W_{t} + sign(W_{t}) d W_{t} (2 W_{t} d W_{t} + dt) $\n",
    "\n",
    "$B_{t}(2 W_{t} d W{t}+ dt) + W_{t}^{2} sign(W_{t}) d W_{t} + sign(W_{t}) d W_{t} (2 W_{t} d W_{t} + dt) =$\n",
    "\n",
    "\n",
    "$ 2 B_{t} W_{t} d W{t} +  B_{t} dt + W_{t}^{2} sign(W_{t}) d W_{t} + 2 sign(W_{t}) W_{t} dt$\n",
    "\n",
    "When we now calculate the expected value we get:\n",
    "\n",
    "as all the terms with a $dW_{t}$ in the end get eliminated we get.\n",
    "\n",
    "$E[B_{t}W_{t}^2] = E[\\int_{0}^{t} B_{s} ds] + 2 E[\\int_{0}^{t} sign(W_{s}) W_{s}ds] $ =\n",
    "\n",
    "$2 E[\\int_{0}^{t} (E[W_{s} 1_{W_{s > 0}} ] - E[W_{s} 1_{W_{s < 0}} ]) ds]$\n",
    "\n",
    "Now we can do a case distinction: \n",
    "\n",
    "(1) $W_{s} > 0$: the term reduces to 2 E[$\\int_{0}^{t} E[W_{s}] $] > 0, as $W_{s}$ is positive.\n",
    "\n",
    "(1) $W_{s} < 0$: the term reduces to 2 E[$\\int_{0}^{t} E[W_{s}] $] > 0, as $W_{s}$ is positive.\n",
    "\n",
    "Hence the integral will always be positive. \n",
    "\n",
    "If we compare this to the expression $ E[ B(t)] E [ W^{2}(t)] $. As $E[ B(t)]$ is 0 the expression is 0.\n",
    "\n",
    "Therefore we showed that the two expressions are unequal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $ S(t) = S(0) e^{\\mu t + \\sigma B(t)}$ under $\\mathbb{P} $. We know that $d S(t) = (\\mu + \\frac{1}{2} \\sigma^{2}) S(t) dt + \\sigma S(t) dB(t)$.\n",
    "\n",
    "What is the distristribution of S(t)\n",
    "How does $ \\tilde{B(t)} $ look like.\n",
    "\n",
    "We know that $ d\\tilde{B(t)} = d B(t) + \\frac{(\\mu + \\frac{1}{2} \\sigma^{2})}{\\sigma} dt $, hence we get the expression $\\tilde{B(t)} = B(t) + \\frac{(\\mu + \\frac{1}{2} \\sigma^{2})}{\\sigma} t  $ \n",
    "\n",
    "I we plug this into d S(t) we get\n",
    "$ (\\mu + \\frac{1}{2} \\sigma^{2}) S(t) dt + \\sigma S(t) dB(t) = \\sigma S(t) d\\tilde{B(t)}$\n",
    "S(t) is clearly a martingale, as the term in front of the dt diminished. \n",
    "\n",
    "The distribution of  S(t) under $ \\tilde{B(t)} $ is lognormal with the parameters adjusted for the change of measure. Under the new probability measure the dynamics of \n",
    "log S(t) are given by \n",
    "\n",
    "$ d(log(S(t))) = - \\frac{1}{2}sigma^{2} dt + \\sigma d\\tilde{B(t)} $.\n",
    "‚Å°\n",
    "So under the new measure log S(t) is normally distributed with mean  $log S(0) - \\frac{1}{2} \\sigma ^{2}t $ and variance $\\sigma ^{2}$ t."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
